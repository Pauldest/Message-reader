"""RSS æºç®¡ç†æ¨¡å—"""

import asyncio
from pathlib import Path
from typing import Optional
import yaml
import aiohttp
import feedparser
import structlog

from .config import FeedSource, get_config

logger = structlog.get_logger()


class FeedManager:
    """RSS æºç®¡ç†å™¨"""
    
    def __init__(self, config_dir: Optional[Path] = None):
        if config_dir is None:
            config_dir = Path(__file__).parent.parent / "config"
        self.config_dir = Path(config_dir)
        self.feeds_path = self.config_dir / "feeds.yaml"
        
        # å¦‚æœä¸å­˜åœ¨ï¼Œä»ç¤ºä¾‹æ–‡ä»¶å¤åˆ¶
        if not self.feeds_path.exists():
            example_path = self.config_dir / "feeds.example.yaml"
            if example_path.exists():
                import shutil
                shutil.copy(example_path, self.feeds_path)
    
    def _load_feeds(self) -> list[dict]:
        """åŠ è½½è®¢é˜…æºåˆ—è¡¨"""
        if not self.feeds_path.exists():
            return []
        
        with open(self.feeds_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f) or {}
        
        return data.get("feeds", [])
    
    def _save_feeds(self, feeds: list[dict]):
        """ä¿å­˜è®¢é˜…æºåˆ—è¡¨"""
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        with open(self.feeds_path, "w", encoding="utf-8") as f:
            yaml.dump(
                {"feeds": feeds},
                f,
                allow_unicode=True,
                default_flow_style=False,
                sort_keys=False,
            )
    
    def list_feeds(self) -> list[FeedSource]:
        """åˆ—å‡ºæ‰€æœ‰è®¢é˜…æº"""
        feeds_data = self._load_feeds()
        return [FeedSource(**f) for f in feeds_data]
    
    def add_feed(self, name: str, url: str, category: str = "æœªåˆ†ç±»") -> bool:
        """æ·»åŠ è®¢é˜…æº"""
        feeds = self._load_feeds()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        for feed in feeds:
            if feed.get("url") == url:
                print(f"âŒ è®¢é˜…æºå·²å­˜åœ¨: {feed.get('name')}")
                return False
        
        # æ·»åŠ æ–°æº
        feeds.append({
            "name": name,
            "url": url,
            "category": category,
            "enabled": True,
        })
        
        self._save_feeds(feeds)
        print(f"âœ… å·²æ·»åŠ è®¢é˜…æº: {name}")
        return True
    
    def remove_feed(self, identifier: str) -> bool:
        """åˆ é™¤è®¢é˜…æºï¼ˆæŒ‰åç§°æˆ– URLï¼‰"""
        feeds = self._load_feeds()
        original_count = len(feeds)
        
        # æŒ‰åç§°æˆ– URL åŒ¹é…
        feeds = [
            f for f in feeds
            if f.get("name") != identifier and f.get("url") != identifier
        ]
        
        if len(feeds) == original_count:
            print(f"âŒ æœªæ‰¾åˆ°è®¢é˜…æº: {identifier}")
            return False
        
        self._save_feeds(feeds)
        print(f"âœ… å·²åˆ é™¤è®¢é˜…æº: {identifier}")
        return True
    
    def toggle_feed(self, identifier: str) -> bool:
        """å¯ç”¨/ç¦ç”¨è®¢é˜…æº"""
        feeds = self._load_feeds()
        
        for feed in feeds:
            if feed.get("name") == identifier or feed.get("url") == identifier:
                feed["enabled"] = not feed.get("enabled", True)
                self._save_feeds(feeds)
                status = "å¯ç”¨" if feed["enabled"] else "ç¦ç”¨"
                print(f"âœ… å·²{status}è®¢é˜…æº: {feed.get('name')}")
                return True
        
        print(f"âŒ æœªæ‰¾åˆ°è®¢é˜…æº: {identifier}")
        return False
    
    async def verify_feed(self, url: str, timeout: int = 10) -> dict:
        """éªŒè¯è®¢é˜…æºæ˜¯å¦æœ‰æ•ˆ"""
        result = {
            "url": url,
            "valid": False,
            "title": None,
            "count": 0,
            "error": None,
        }
        
        try:
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=timeout)
            ) as session:
                async with session.get(url) as response:
                    if response.status != 200:
                        result["error"] = f"HTTP {response.status}"
                        return result
                    
                    content = await response.text()
                    parsed = feedparser.parse(content)
                    
                    if parsed.bozo and not parsed.entries:
                        result["error"] = "æ— æ•ˆçš„ RSS/Atom æ ¼å¼"
                        return result
                    
                    result["valid"] = True
                    result["title"] = parsed.feed.get("title", "æœªçŸ¥")
                    result["count"] = len(parsed.entries)
                    
                    return result
        
        except asyncio.TimeoutError:
            result["error"] = "è¿æ¥è¶…æ—¶"
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    async def verify_all_feeds(self) -> list[dict]:
        """éªŒè¯æ‰€æœ‰è®¢é˜…æº"""
        feeds = self.list_feeds()
        
        if not feeds:
            print("ğŸ“­ æ²¡æœ‰é…ç½®ä»»ä½•è®¢é˜…æº")
            return []
        
        print(f"ğŸ” æ­£åœ¨éªŒè¯ {len(feeds)} ä¸ªè®¢é˜…æº...\n")
        
        results = []
        for feed in feeds:
            result = await self.verify_feed(feed.url)
            result["name"] = feed.name
            result["enabled"] = feed.enabled
            results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            if result["valid"]:
                status = "âœ…" if feed.enabled else "â¸ï¸"
                print(f"{status} {feed.name}: {result['count']} ç¯‡æ–‡ç« ")
            else:
                print(f"âŒ {feed.name}: {result['error']}")
        
        return results


def print_feeds_table(feeds: list[FeedSource]):
    """æ‰“å°è®¢é˜…æºè¡¨æ ¼"""
    if not feeds:
        print("ğŸ“­ æ²¡æœ‰é…ç½®ä»»ä½•è®¢é˜…æº")
        print("ä½¿ç”¨ 'python -m src.feeds add <åç§°> <URL>' æ·»åŠ è®¢é˜…æº")
        return
    
    print(f"\nğŸ“° å…± {len(feeds)} ä¸ªè®¢é˜…æº:\n")
    print(f"{'çŠ¶æ€':<4} {'åç§°':<20} {'åˆ†ç±»':<10} {'URL'}")
    print("-" * 80)
    
    for feed in feeds:
        status = "âœ…" if feed.enabled else "â¸ï¸"
        name = feed.name[:18] + ".." if len(feed.name) > 20 else feed.name
        category = feed.category[:8] + ".." if len(feed.category) > 10 else feed.category
        url = feed.url[:40] + "..." if len(feed.url) > 43 else feed.url
        print(f"{status:<4} {name:<20} {category:<10} {url}")


def main():
    """RSS æºç®¡ç† CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="RSS æºç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python -m src.feeds list                    # åˆ—å‡ºæ‰€æœ‰è®¢é˜…æº
  python -m src.feeds add å°‘æ•°æ´¾ https://sspai.com/feed ç§‘æŠ€
                                              # æ·»åŠ è®¢é˜…æº
  python -m src.feeds remove å°‘æ•°æ´¾           # åˆ é™¤è®¢é˜…æº
  python -m src.feeds verify                  # éªŒè¯æ‰€æœ‰è®¢é˜…æº
  python -m src.feeds verify https://...      # éªŒè¯å•ä¸ª URL
  python -m src.feeds toggle å°‘æ•°æ´¾           # å¯ç”¨/ç¦ç”¨è®¢é˜…æº
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")
    
    # list å‘½ä»¤
    subparsers.add_parser("list", aliases=["ls"], help="åˆ—å‡ºæ‰€æœ‰è®¢é˜…æº")
    
    # add å‘½ä»¤
    add_parser = subparsers.add_parser("add", help="æ·»åŠ è®¢é˜…æº")
    add_parser.add_argument("name", help="è®¢é˜…æºåç§°")
    add_parser.add_argument("url", help="RSS/Atom URL")
    add_parser.add_argument("category", nargs="?", default="æœªåˆ†ç±»", help="åˆ†ç±»ï¼ˆå¯é€‰ï¼‰")
    
    # remove å‘½ä»¤
    remove_parser = subparsers.add_parser("remove", aliases=["rm", "delete"], help="åˆ é™¤è®¢é˜…æº")
    remove_parser.add_argument("identifier", help="è®¢é˜…æºåç§°æˆ– URL")
    
    # verify å‘½ä»¤
    verify_parser = subparsers.add_parser("verify", aliases=["check", "test"], help="éªŒè¯è®¢é˜…æº")
    verify_parser.add_argument("url", nargs="?", help="è¦éªŒè¯çš„ URLï¼ˆå¯é€‰ï¼Œä¸å¡«åˆ™éªŒè¯å…¨éƒ¨ï¼‰")
    
    # toggle å‘½ä»¤
    toggle_parser = subparsers.add_parser("toggle", help="å¯ç”¨/ç¦ç”¨è®¢é˜…æº")
    toggle_parser.add_argument("identifier", help="è®¢é˜…æºåç§°æˆ– URL")
    
    args = parser.parse_args()
    manager = FeedManager()
    
    if args.command in ("list", "ls", None):
        feeds = manager.list_feeds()
        print_feeds_table(feeds)
    
    elif args.command == "add":
        # å…ˆéªŒè¯ URL
        print(f"ğŸ” æ­£åœ¨éªŒè¯ {args.url}...")
        result = asyncio.run(manager.verify_feed(args.url))
        
        if result["valid"]:
            print(f"âœ… æœ‰æ•ˆï¼å‘ç° {result['count']} ç¯‡æ–‡ç« ")
            # å¦‚æœæ²¡æœ‰æŒ‡å®šåç§°ï¼Œä½¿ç”¨ feed çš„æ ‡é¢˜
            name = args.name or result["title"]
            manager.add_feed(name, args.url, args.category)
        else:
            print(f"âŒ éªŒè¯å¤±è´¥: {result['error']}")
            confirm = input("æ˜¯å¦ä»è¦æ·»åŠ ï¼Ÿ(y/N): ")
            if confirm.lower() == "y":
                manager.add_feed(args.name, args.url, args.category)
    
    elif args.command in ("remove", "rm", "delete"):
        manager.remove_feed(args.identifier)
    
    elif args.command in ("verify", "check", "test"):
        if args.url:
            print(f"ğŸ” æ­£åœ¨éªŒè¯ {args.url}...")
            result = asyncio.run(manager.verify_feed(args.url))
            
            if result["valid"]:
                print(f"\nâœ… è®¢é˜…æºæœ‰æ•ˆ!")
                print(f"   æ ‡é¢˜: {result['title']}")
                print(f"   æ–‡ç« æ•°: {result['count']}")
            else:
                print(f"\nâŒ éªŒè¯å¤±è´¥: {result['error']}")
        else:
            asyncio.run(manager.verify_all_feeds())
    
    elif args.command == "toggle":
        manager.toggle_feed(args.identifier)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
